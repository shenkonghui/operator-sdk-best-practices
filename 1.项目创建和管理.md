# 项目初始与管理

## 简述

operator-sdk框架基于golang语言开发，专门为了operator进行设计，可以使用框架快速生成crd，controller代码，以及简化部署等等，把更多时间专心关注资源的实现逻辑。



## 安装

安装就直接参考官方文档进行安装，

https://sdk.operatorframework.io/build/

安装完毕后可以看到版本号

```
 ~/src/tmp  operator-sdk version
operator-sdk version: "v0.18.1", commit: "7bf7b6886d647dc202525daec16fab67dcc52a3d", kubernetes version: "v1.18.2", go version: "go1.13.6 darwin/amd64"
```



## 初始化

### 创建项目

创建一个项目命名为 example-operator 的golang项目，如果路径不在gopath，需要声明一下你的自定义repo. 

因为主要用go mod进行管理项目，直接使用vendor进行依赖管理，不用在gopath里面也没有关系

```
operator-sdk new example-operator --repo github.com/example-operator
```

如果定义了repo，那么go.mod文件第一行就是

```
module github.com/example-operator
```

执行后出现了如下输出，代码项目初始化成功

```
 ~/src/tmp  operator-sdk new example-operator --repo github.com/example-operator
INFO[0000] Creating new Go operator 'example-operator'.
INFO[0000] Created go.mod
INFO[0000] Created tools.go
INFO[0000] Created cmd/manager/main.go
INFO[0000] Created build/Dockerfile
INFO[0000] Created build/bin/entrypoint
INFO[0000] Created build/bin/user_setup
INFO[0000] Created deploy/service_account.yaml
INFO[0000] Created deploy/role.yaml
INFO[0000] Created deploy/role_binding.yaml
INFO[0000] Created deploy/operator.yaml
INFO[0000] Created pkg/apis/apis.go
INFO[0000] Created pkg/controller/controller.go
INFO[0000] Created version/version.go
INFO[0000] Created .gitignore
INFO[0000] Validating project
INFO[0016] Project validation successful.
INFO[0016] Project creation complete.
```

查看一下目录结构

```
 ~/src/tmp/example-operator  tree
.
├── build
│   ├── Dockerfile
│   └── bin
│       ├── entrypoint
│       └── user_setup
├── cmd
│   └── manager
│       └── main.go
├── deploy
│   ├── operator.yaml
│   ├── role.yaml
│   ├── role_binding.yaml
│   └── service_account.yaml
├── go.mod
├── go.sum
├── pkg
│   ├── apis
│   │   └── apis.go
│   └── controller
│       └── controller.go
├── tools.go
└── version
    └── version.go
```

实际关注的文件夹/文件主要是以下几个

- build

  编译过程中生成的二进制文件、dockerfile等等, 一般不会去动

- cmd

  代码启动的主要main文件, 一般也不会去动

- pkg

  包括api的定义、controller文件、以及自定义代码实现文件，主要编码的地方

- deploy

  实际部署到K8s中的yaml文件，包括crd、cr、role、sa、rolebinds、deployment文件

  

### 创建api与controller

api也就是你的crd自定义资源结构，也就是你最终apply的yaml文件的最终数据格式。

controller将是你管理资源的的主要方式，这块逻辑需要自己进行实现。



下面这个命令完成了如下功能。

创建api group 为 app.example.com、版本为v1alpha1、资源类型为AppService.

创建controller与api格式相同



```
~/src/tmp/example-operator  operator-sdk add api --api-version=app.example.com/v1alpha1 --kind=AppService
INFO[0000] Generating api version app.example.com/v1alpha1 for kind AppService.
INFO[0000] Created pkg/apis/app/group.go
INFO[0002] Created pkg/apis/app/v1alpha1/appservice_types.go
INFO[0002] Created pkg/apis/addtoscheme_app_v1alpha1.go
INFO[0002] Created pkg/apis/app/v1alpha1/register.go
INFO[0002] Created pkg/apis/app/v1alpha1/doc.go
INFO[0002] Created deploy/crds/app.example.com_v1alpha1_appservice_cr.yaml
INFO[0002] Running deepcopy code-generation for Custom Resource group versions: [app:[v1alpha1], ]
INFO[0015] Code-generation complete.
INFO[0015] Running CRD generator.
INFO[0016] CRD generation complete.
INFO[0016] API generation complete.
INFO[0016] API generation complete.


 ~/src/tmp/example-operator  operator-sdk add controller --api-version=app.example.com/v1alpha1 --kind=AppService
INFO[0000] Generating controller version app.example.com/v1alpha1 for kind AppService.
INFO[0000] Created pkg/controller/appservice/appservice_controller.go
INFO[0000] Created pkg/controller/add_appservice.go
INFO[0000] Controller generation complete.
```



#### api

创建api的时候，自动生成了以下文件

- deploy/crds 

  crd的主要部署文件，包括crd(custom resource definition)和demo cr(custom resource)

- pkg/api/$name

  $name取--api-version 参数的第一个“.” 前面进行的字符串

一般主要的api文件在 `pkg/apis/$name/$version/$kind_type.go`

本项目是`pkg/apis/app/v1alpha/appservice_types.go`

默认包括kind、Spec、Status、List这几个结构体

```
type AppServiceSpec struct {
}

type AppServiceStatus struct {
}

type AppService struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	Spec   AppServiceSpec   `json:"spec,omitempty"`
	Status AppServiceStatus `json:"status,omitempty"`
}

type AppServiceList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []AppService `json:"items"`
}
```



#### controller

创建controller的时候，会自动创建一个demo，主要功能就是根据crd创建一个pod。

主要自动生成了以下文件

controller文件在`pkg/controller/$name/$kind_controller.go`

主要会使用的2个方法 `add` 和 `Reconcile`

- `add`方法可以为k8s资源设置list-watch处理流程，可以定义需要监听的事件，做精细化的工作，比如pod状态变更，然后做处理
- `Reconcile`方法类似一个上面的一个汇总的作用，不管是自定义的crd，还是在上述add中的任何消息事件都可以选择进入这里，通常用来作为最后状态的保存。 



add方法中添加了controller，同时设置了对crd和pod资源设置了监听

```
// 创建一个新的controller
func add(mgr manager.Manager, r reconcile.Reconciler) error {
	// 创建controller
	c, err := controller.New("appservice-controller", mgr, controller.Options{Reconciler: r})
	if err != nil {
		return err
	}

	// 监听crd资源的变动
	err = c.Watch(&source.Kind{Type: &appv1alpha1.AppService{}}, &handler.EnqueueRequestForObject{})
	if err != nil {
		return err
	}

  //监听pod的变动
	err = c.Watch(&source.Kind{Type: &corev1.Pod{}}, &handler.EnqueueRequestForOwner{
		IsController: true,
		OwnerType:    &appv1alpha1.AppService{},
	})
	if err != nil {
		return err
	}

	return nil
}

```

在add中设置了pod和crd的监听，一旦pod和crd资源在etcd中发生变更，就会进入Reconcile方法。

Reconcile方法本次实现的是监听AppService资源对象的状态，如果在该namespace下面找不到对应名称的pod，就创建pod。

```
func (r *ReconcileAppService) Reconcile(request reconcile.Request) (reconcile.Result, error) {

	instance := &appv1alpha1.AppService{}
	err := r.client.Get(context.TODO(), request.NamespacedName, instance)
	if err != nil {
		if errors.IsNotFound(err) {
			return reconcile.Result{}, nil
		}
		return reconcile.Result{}, err
	}

	pod := newPodForCR(instance)

	if err := controllerutil.SetControllerReference(instance, pod, r.scheme); err != nil {
		return reconcile.Result{}, err
	}

	found := &corev1.Pod{}
	err = r.client.Get(context.TODO(), types.NamespacedName{Name: pod.Name, Namespace: pod.Namespace}, found)
	if err != nil && errors.IsNotFound(err) {
		reqLogger.Info("Creating a new Pod", "Pod.Namespace", pod.Namespace, "Pod.Name", pod.Name)
		err = r.client.Create(context.TODO(), pod)
		if err != nil {
			return reconcile.Result{}, err
		}

		return reconcile.Result{}, nil
	} else if err != nil {
		return reconcile.Result{}, err
	}

	return reconcile.Result{}, nil
}
```

newPodForCR方法,定义了如何从AppService对象创建一个pod对象。

```
// newPodForCR returns a busybox pod with the same name/namespace as the cr
func newPodForCR(cr *appv1alpha1.AppService) *corev1.Pod {
	labels := map[string]string{
		"app": cr.Name,
	}
	return &corev1.Pod{
		ObjectMeta: metav1.ObjectMeta{
			Name:      cr.Name + "-pod",
			Namespace: cr.Namespace,
			Labels:    labels,
		},
		Spec: corev1.PodSpec{
			Containers: []corev1.Container{
				{
					Name:    "busybox",
					Image:   "busybox",
					Command: []string{"sleep", "3600"},
				},
			},
		},
	}
}
```



注意：

如果后期更新了api、那么需要同时更新一下，因为需要重新更新crd等相关自动生成的文件.

```
operator-sdk generate crds
operator-sdk generate k8s
```



## 本地调试

1. 首先需要一个集群，同时已经配置好kube文件。

可以看到服务端和客户端的信息

```
~/src/tmp/example-operator  kubectl version
Client Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.6", GitCommit:"96fac5cd13a5dc064f7d9f4f23030a6aeface6cc", GitTreeState:"clean", BuildDate:"2019-08-19T11:13:49Z", GoVersion:"go1.12.9", Compiler:"gc", Platform:"darwin/amd64"}
Server Version: version.Info{Major:"1", Minor:"17", GitVersion:"v1.17.2", GitCommit:"59603c6e503c87169aea6106f57b9f242f64df89", GitTreeState:"clean", BuildDate:"2020-01-18T23:22:30Z", GoVersion:"go1.13.5", Compiler:"gc", Platform:"linux/amd64"}
```



2. 安装crd

```
~/src/tmp/example-operator  kubectl apply -f deploy/crds/app.example.com_appservices_crd.yaml 
customresourcedefinition.apiextensions.k8s.io/appservices.app.example.com created

```



3. 设置环境变量WATCH_NAMESPACE

   代表需要监听的namespace，空字符串代表所有namespace

   

4. 直接run 或者 debug  cmd/manager/main.go 文件，当做一个普通的golang项目运行即可. 可以项目已经成功运行起来了


```
{"level":"info","ts":1593947019.4262998,"logger":"cmd","msg":"Operator Version: 0.0.1"}
{"level":"info","ts":1593947019.426354,"logger":"cmd","msg":"Go Version: go1.13"}
{"level":"info","ts":1593947019.426363,"logger":"cmd","msg":"Go OS/Arch: darwin/amd64"}
{"level":"info","ts":1593947019.426369,"logger":"cmd","msg":"Version of operator-sdk: v0.18.1"}
{"level":"info","ts":1593947019.430063,"logger":"leader","msg":"Trying to become the leader."}
{"level":"info","ts":1593947019.430112,"logger":"leader","msg":"Skipping leader election; not running in a cluster."}
I0705 19:03:40.909559    4625 request.go:621] Throttling request took 1.003237457s, request: GET:https://10.1.11.76:6443/apis/rbac.istio.io/v1alpha1?timeout=32s
{"level":"info","ts":1593947021.302305,"logger":"controller-runtime.metrics","msg":"metrics server is starting to listen","addr":"0.0.0.0:8383"}
{"level":"info","ts":1593947021.302479,"logger":"cmd","msg":"Registering Components."}
{"level":"info","ts":1593947024.630014,"logger":"cmd","msg":"Could not create metrics Service","error":"failed to initialize service object for metrics: OPERATOR_NAME must be set"}
{"level":"info","ts":1593947026.2191381,"logger":"cmd","msg":"Could not create ServiceMonitor object","error":"no ServiceMonitor registered with the API"}
{"level":"info","ts":1593947026.2191901,"logger":"cmd","msg":"Install prometheus-operator in your cluster to create ServiceMonitor objects","error":"no ServiceMonitor registered with the API"}
{"level":"info","ts":1593947026.2192059,"logger":"cmd","msg":"Starting the Cmd."}
{"level":"info","ts":1593947026.219429,"logger":"controller-runtime.manager","msg":"starting metrics server","path":"/metrics"}
{"level":"info","ts":1593947026.219564,"logger":"controller-runtime.controller","msg":"Starting EventSource","controller":"appservice-controller","source":"kind source: /, Kind="}
{"level":"info","ts":1593947026.423678,"logger":"controller-runtime.controller","msg":"Starting EventSource","controller":"appservice-controller","source":"kind source: /, Kind="}
{"level":"info","ts":1593947026.724263,"logger":"controller-runtime.controller","msg":"Starting Controller","controller":"appservice-controller"}
{"level":"info","ts":1593947026.724315,"logger":"controller-runtime.controller","msg":"Starting workers","controller":"appservice-controller","worker count":1}

```



5. 部署cr文件，之前再生成api的时候已经创建了一个demo的cr文件,  内容如下(spec.size在newPodForCR方法中没有使用)

   我们现在开始创建

```
apiVersion: app.example.com/v1alpha1
kind: AppService
metadata:
  name: example-appservice
spec:
  # Add fields here
  size: 3
```

```
kubectl apply -f deploy/crds/app.example.com_v1alpha1_appservice_cr.yaml 
```



看到控制台打印了如下日志

```
{"level":"info","ts":1593947237.5451279,"logger":"controller_appservice","msg":"Creating a new Pod","Request.Namespace":"test","Request.Name":"example-appservice","Pod.Namespace":"test","Pod.Name":"example-appservice-pod"}

```

再来看看当前的pod，发现刚刚已经创建了pod
```
 ~/src/tmp/example-operator  kubectl get pod 
NAME                     READY   STATUS    RESTARTS   AGE
example-appservice-pod   1/1     Running   0          9s

```
再次尝试删除资源，也可以发现pod被删除(这里的删除不是代码实现，而是k8s中资源级联删除的机制，在代码中通过SetControllerReference设置appservice为该pod的owen，所有一旦owen被删除，他所创建的所有资源都会被删除)

```
~/src/tmp/example-operator  kubectl delete  -f deploy/crds/app.example.com_v1alpha1_appservice_cr.yaml
appservice.app.example.com "example-appservice" deleted
```

这就是这个demo主要的功能，可以尝试更复杂的逻辑



## 部署operator到集群

当代码已经调试通过以后，最后肯定是需要以pod的方式运行在集群中，那么就需要打包成docker镜像，运行在K8s中，可以按照以下的流程进行部署。

1. 编译生成镜像

2. 推送镜像

3. 编辑operator.yaml 中镜像地址以及相关环境变量

4. 创建crd、role、sa、rolding, 根据实际的权限以及namespace进行修改

5. 创建operator

   

```
# 编译镜像
operator-sdk build hello-world:v0.1

# 推送
docker push hello-world:v0.1

# 安装crd
kubectl apply -f deploy/crds/xxx_crds.yaml

# 安装role、sa、rolebind和operator
kubectl apply -f deploy

```



## 总结

创建框架主要是这个流程，这也是刚刚开始开发，框架中隐藏了很多实现的细节，比如list watch机制、全局锁等机制，后面的文章会根据实际案例进行详细说明。